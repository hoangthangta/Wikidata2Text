# Wikidata2Text
We do the task of translating Wikidata claims or statements, organized as a set of triples or quadruples to Wikipedia sentences. This paper will be submitted to http://www.semantic-web-journal.net/ soon. Please check the guideline to follow when we publish our paper. The code is mainly about the data mapping process.

# Data
We have two folders for the data:
* Our_data: is the folder containing all of our data for the paper.
* Data: this folder is for the experiment, we already set some data files for testing purposes here.

# How to collect data
At first, we have to collect the pair of (item, page) via Wikidata query server. In this project, we store 6 files for 6 Wikidata properties: 
* data/p108.csv
* data/p166.csv
* data/p26.csv
* data/p39.csv
* data/p54.csv
* data/p69.csv
